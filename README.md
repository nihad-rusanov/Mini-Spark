## ğŸ“Š MiniSpark â€“ Lightweight Data Processing Engine with SQL & Web UI

**MiniSpark** is a simplified, Spark-inspired data processing engine built in Python. It supports map/filter/reduce operations on large datasets and provides a web-based UI where users can upload CSV files and execute basic SQL-like queries.

---

## ğŸš€ Features

* Lightweight RDD engine (Resilient Distributed Dataset)
* Lazy evaluation with collect()
* Basic SQL query support (SELECT, WHERE with comparison ops)
* CSV/JSON file loading
* Web UI (Flask-based)
* Ready for deployment on platforms like Render

---

## ğŸ§  How It Works

Under the hood, MiniSpark:

* Parses your SQL query into RDD operations
* Builds a DAG (Directed Acyclic Graph) of operations
* Executes the DAG lazily when `collect()` is triggered
* Returns results to the browser

---

## ğŸ’» Tech Stack

* Python 3.10
* Flask (Web UI)
* Gunicorn (WSGI server)
* CSV/JSON file parsing

---

## ğŸŒ Live Demo (if applicable)

> Deployed on [Render](https://mini-spark-1.onrender.com/)
> Upload your own dataset and try a query like:
> `SELECT name FROM products WHERE price > 1000`

---

## ğŸ” SQL Query Limitations

Only simple queries are supported:

```sql
SELECT <column> FROM products WHERE <column> <operator> <value>
```

* Supported operators: `=`, `>`, `<`, `>=`, `<=`
* Only one `SELECT` column
* Only one condition in `WHERE`
* No support for `AND`, `OR`, `JOIN`, etc.
* String values don't require quotes: `category = Stationery`

---

## ğŸ“ Project Structure

```
mini-spark/
â”œâ”€â”€ app/                # Flask application
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ routes.py
â”‚   â”œâ”€â”€ templates/
â”‚   â””â”€â”€ static/
â”œâ”€â”€ rdd.py              # RDD implementation
â”œâ”€â”€ sql_parser.py       # SQL to RDD translator
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ file_io.py      # CSV / JSON helpers
â”œâ”€â”€ web_main.py         # App entry point
â”œâ”€â”€ requirements.txt
â””â”€â”€ render.yaml
```

---

## âš™ï¸ Running Locally

### 1. Clone the project

```bash
git clone https://github.com/nihad-rusanov/Mini-Spark.git
cd Mini-Spark
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Run the web app

```bash
python web_main.py
```

Visit `http://localhost:5000`

---

## â˜ï¸ Deployment (Render.com)

If you're deploying without Docker:

* Ensure you have:

  * `requirements.txt`
  * `render.yaml`

### Example Render configuration:

```yaml
services:
  - type: web
    name: mini-spark
    runtime: python
    buildCommand: pip install -r requirements.txt
    startCommand: gunicorn web_main:app --bind=0.0.0.0:$PORT
```

---

## ğŸ§ª Example Dataset

You can generate a 100,000-row realistic dataset using:

```bash
python generate_products_csv.py
```

Or use your own CSV with columns like:

```
id,name,category,price,stock
1,Laptop,Electronics,1200.00,10
...
```

---

## âœ… TODO / Future Enhancements

* Support for multiple SELECT columns
* Support for `AND` / `OR` in SQL WHERE
* Aggregation functions: `COUNT`, `AVG`, `SUM`
* GroupBy operations
* Web-based DAG visualization
* Parallel map execution

---

## ğŸ“œ License

MIT License â€“ use freely, contribute openly.
